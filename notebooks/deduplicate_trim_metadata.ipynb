{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path(\"../data\")\n",
    "# Note that these columns have different names in the original file\n",
    "# (run_metadata.v05.tsv, 514a111c8f2f02c2db36a3e4e48baf58):\n",
    "# strain = Run\n",
    "# date_submitted = First_created\n",
    "# date = Date_tree\n",
    "metadata_file = base_dir / \"run_metadata.v05.renamed.tsv\"\n",
    "md = pd.read_csv(\n",
    "    metadata_file,\n",
    "    header=0,\n",
    "    sep=\"\\t\",\n",
    "    na_values=[\".\"],\n",
    ")\n",
    "#md.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not len(md['strain'].unique()) == len(md['Sample'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Address https://github.com/jeromekelleher/sc2ts/issues/257\n",
    "# ENA sample accessions\n",
    "dup_samples = md[md.duplicated(subset='Sample')]['Sample'].unique()\n",
    "\n",
    "# Prefilter metadata to only the samples above.\n",
    "filt_md = md[md['Sample'].isin(dup_samples)]\n",
    "\n",
    "# Keep a replicate sequence for each sample that has multiple sequences.\n",
    "best_seqs = []\n",
    "no_tiebreaker_seqs = []\n",
    "\n",
    "num_rep_seqs_total = 0\n",
    "num_rep_seqs_removed = 0\n",
    "\n",
    "for i in tqdm.tqdm(range(len(dup_samples))):\n",
    "    tmp_sample = dup_samples[i]\n",
    "    tmp_df = filt_md[filt_md['Sample'] == tmp_sample].reset_index()\n",
    "    assert len(tmp_df) - 1 > 0\n",
    "\n",
    "    num_rep_seqs_total += len(tmp_df)\n",
    "\n",
    "    arr_cons_het = tmp_df['Viridian_cons_het'].to_numpy()\n",
    "    arr_N = tmp_df['Viridian_N'].to_numpy()\n",
    "    arr_cons_len = tmp_df['Viridian_cons_len'].to_numpy()\n",
    "\n",
    "    # Lots of runtime warnings generated due to presence of NA entries.\n",
    "    for arr, fn in [\n",
    "        (arr_cons_het, np.nanmin),  # Try to pick seq with fewest non-ACGTN bases\n",
    "        (arr_N, np.nanmin), # Try to pick seq with fewest Ns\n",
    "        (arr_cons_len, np.nanmax),  # Try to pick longest seq\n",
    "    ]:\n",
    "        best_value = fn(arr)\n",
    "        if not np.isnan(best_value):\n",
    "            best_indices = np.where(arr == best_value)[0]\n",
    "            if len(best_indices) == 1:\n",
    "                best_seqs.append(\n",
    "                    tmp_df.iloc[best_indices[0]]['strain']\n",
    "                )\n",
    "                break\n",
    "    else:\n",
    "        # Arbitrarily choose the first replicate sequence.\n",
    "        no_tiebreaker_seqs.append(\n",
    "            tmp_df.iloc[0]['strain']\n",
    "        )\n",
    "\n",
    "    # Because one replicate sequence is added either way.\n",
    "    num_rep_seqs_removed += len(tmp_df) - 1\n",
    "\n",
    "\n",
    "assert len(dup_samples) == len(best_seqs) + len(no_tiebreaker_seqs)\n",
    "print(f\"Duplicate samples: {len(dup_samples)}\")\n",
    "print(f\"Replicate sequences selected based on above criteria: {len(best_seqs)}\")\n",
    "print(f\"Replicate sequences when there are no tie breakers: {len(no_tiebreaker_seqs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_seqs = best_seqs + no_tiebreaker_seqs\n",
    "rep_seqs_to_exclude = filt_md[~filt_md['strain'].isin(keep_seqs)]['strain']\n",
    "assert len(filt_md) == len(keep_seqs) + len(rep_seqs_to_exclude)\n",
    "\n",
    "md_dedup = md[~md['strain'].isin(rep_seqs_to_exclude)].reset_index()\n",
    "assert len(md) - len(md_dedup) == len(rep_seqs_to_exclude)\n",
    "assert len(md['Sample'].unique()) == len(md_dedup['Sample'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Address https://github.com/jeromekelleher/sc2ts/issues/273\n",
    "md_dedup_trimmed = md_dedup[\n",
    "    [\n",
    "        'Sample',\n",
    "        'strain',\n",
    "        'Platform',\n",
    "        'Country',\n",
    "        'date',\n",
    "        'Viridian_result',\n",
    "        'In_Viridian_tree',\n",
    "        'Viridian_pangolin',\n",
    "        'Viridian_scorpio',\n",
    "        'Viridian_pangolin_1.29',\n",
    "        'Viridian_scorpio_1.29',\n",
    "        'Viridian_N',\n",
    "        'Viridian_cons_het',\n",
    "        'Viridian_cons_len',\n",
    "    ]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_metadata_file = base_dir / \"run_metadata.v05.renamed.dedup.trimmed.tsv\"\n",
    "md_dedup_trimmed.to_csv(out_metadata_file, sep=\"\\t\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(out_metadata_file, sep=\"\\t\")\n",
    "assert len(test_df['strain'].unique()) == len(test_df['Sample'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
